# 进程和线程

```
进程：
一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在Windows系统中，一个运行的xx.exe就是一个进程。
线程：
1.线程是进程当中的一条执行流程。
2.每个线程拥有独立的虚拟机栈、本地方法栈和程序计数器(pc)，线程切换的开销小
3.一个进程中的多个线程共享相同的内存地址空间—》它们从同一堆中分配对象，可以访问相同的变量和对象。
根本区别：线程是处理器任务调度和执行的基本单位，而进程则是资源分配的基本单位

线程相比进程能减少资源开销，体现在：
1.线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
2.线程之间切换的开销比较小。
```

从 JVM 角度说进程和线程之间的关系

<img src="https://img-blog.csdnimg.cn/20191105205545651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua3dvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)*资源，但是每个线程有自己的程序计数器**、**虚拟机栈** 和 **本地方法栈**。

## 进程的状态

```
1.创建状态(new) ：进程正在被创建，尚未到就绪状态。
2.就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
3.运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
4.阻塞状态(waiting) ：进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。
5.结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。
```

## 进程的上下文切换

```
各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。常见的进程上下文切换场景：

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
- 进程在系统资源不足（比如内存不足，等待输入输出操作）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；
```

## 进程的调度算法

```
非抢占式调度算法：挑选一个进程，然后一直运行直到被阻塞或者到进程退出，才调用另一个进程。
抢占式调度算法：挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。

1.先来先服务调度算法：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。
2.最短作业优先调度算法：它会优先选择运行时间最短的进程来运行，对长作业不利。
3.高响应比优先调度算法：每次进行进程调度时，先计算「响应比优先级=（等待时间+要求服务时间）/ 要求服务时间」，然后把「响应比优先级」最高的进程投入运行。要求服务时间是无法准确计算的。
4.时间片轮转调度算法：每个进程被分配一个时间段，允许该进程在该时间段运行。时间一到就挂起进程，cpu分配给另外进程

5.最高优先级调度算法：从就绪队列中选择最高优先级的进程进行运行。优选级分为静态优选级和动态优选级。
静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
动态优先级：根据进程的动态变化调整优先级，如随着时间的推移增加等待进程的优先级。

6.多级反馈队列调度算法：「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；
```

![多级反馈队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/34-%E9%93%B6%E8%A1%8C-%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88.jpg)

1.设置多个排队队列，且每个队列的优先级不同，优选级越高的时间片越短。
2.新进程来了，先进入第一级队列的末尾，按先来先服务原则等待调度。如果时间片用完，进程的业务还没有办理完成，则进入下一级队列的末尾。以此类推，直到办理完成。
3.当第一级队列没人排队时，则调度第二级队列的进程。如果期间出现新进程加入到较高优先级的队列，则暂停目前进程，优先处理高优先级进程。



## 进程的通信方式

```
1.匿名管道：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信，因为这种管道没有实体文件，所以只能通过fork来复制父进程的文件描述符。
2.有名管道: 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

3.消息队列：消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据块。消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。缺点一是通信不及时，二是队列也有大小限制。

4.共享内存：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。存在进程竞争冲突的问题。

5.信号量：一个整型的计数器，主要用于实现进程间的互斥与同步。信号量表示可用资源的数量。控制信号量两个方式：P操作信号量减1，v操作信号量加1。信号量小于0，代表资源被占用。

6.信号：信号是进程间通信机制中唯一的异步通信机制，可以在任何时候发送信号给某一进程。Ctrl+C产生SIGINT信号，表示终止该进程；
7.socket:主要用于不同主机的进程间通信，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。
```

## 死锁的四个条件和解决

```
1.资源互斥：多个线程不能同时使用同一个资源。资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
2.占有并等待：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
3.非抢占：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
4.环路等待：在死锁发生的时候，两个线程获取资源的顺序构成了环形链。有一组等待进程 {P0, P1,..., Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，......，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。

死锁的表现：点击确定或保存按钮，程序没有响应，也没有出现报错

死锁解决的办法
1.死锁防止
死锁防止的策略就是至少破坏这四个条件其中一项。
破坏资源互斥条件：使资源同时访问而非互斥使用，就没有进程会阻塞在资源上，从而不发生死锁。
破坏占有和等待条件：进程必须在执行之前就申请需要的全部资源
破坏不剥夺条件：占有资源的进程若要申请新资源，必须主动释放已占有资源，若需要此资源，应该向系统重新申请。

2.死锁避免
各种死锁防止方法能够防止发生死锁，但必然会降低系统并发性，导致低效的资源利用率。在程序运行时避免发生死锁。
涉及到银行家算法，会先判断一个状态是否是安全的，不安全拒绝进入

3.死锁检测和恢复
不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。
死锁检测算法：
每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。
```

## 线程崩溃，进程一定会崩溃吗（JVM除外）

```
一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃。因为在进程中，各个线程的地址空间是共享的，某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的。因此系统把进程崩溃。
进程崩溃原理：
1.CPU 执行正常的进程指令
2.调用 kill 系统调用向进程发送信号
3.进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统
4.调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）
5.操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出。如果进程注册了自己的信号处理函数，则会执行自己的信号处理函数。

线程崩溃，但是JVM进程不会崩溃的原因：JVM自定义了信号处理函数，做了额外的处理不让JVM崩溃。恢复了线程的执行，并抛出异常。
```

## 锁的类型

```
互斥锁：互斥锁是一种「独占锁」，加锁失败之后，线程会释放cpu，进入阻塞状态。直到锁被释放后，才被唤醒线程进行锁的竞争。这里出现两次线程的上下文切换。所以如果能确定等待锁时间很短，就应该用自旋锁。让它自旋一下，不进行线程切换。

自旋锁：使用CAS函数，来完成加锁和解锁操作，不主动发生线程上下文切换。比较和替换是原子操作。加锁失败自旋等待重试。

```



# 虚拟内存管理

操作系统为每个进程分配独立的一套虚拟地址，从而隔离开来。为了将虚拟地址和物理地址联系起来，有内存分段和内存分页两种方式。

## 1.内存分段

段式管理把主存分为一段段的，段是有实际意义的。每个段定义了一组逻辑信息，例如,有主程序段、子程序段、数据段 及栈段等。分段机制下是如何做到虚拟地址和物理地址映射的？分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。

<img src="https://img-blog.csdnimg.cn/a9ed979e2ed8414f9828767592aadc21.png" alt="img" style="zoom: 50%;" />

段选择因子里面最重要的是段号，用作段表的索引，段表保存了段的基地址（起始地址），段的界限（段的范围）等。
段内偏移量表示在段的偏移位置，因此段的起始地址+段内偏移量 = 物理内存地址。

![img](https://img-blog.csdnimg.cn/c5e2ab63e6ee4c8db575f3c7c9c85962.png)

如果要访问段3中的偏移量500的虚拟地址，我们可计算出物理地址为 段3基地址7000 + 偏移量500 = 7500

缺点：会出现内存外部碎片，这是因为段式内存管理要求分配的 整段内存空间是连续的。为了处理内存碎片，可用使用内存交换，但是硬盘的速度比内存慢太多。每次内存交换，我们都需要把一大段连续的内存数据写到硬盘上，因此内存交换效率低。



## 2.内存分页

内存分页管理：分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，称为页。在Linux，每一页的大小为4kB。虚拟地址与物理地址之间通过页表来映射。页表是存储在内存里的，内存管理单元 (MMU)就将虚拟内存地址转换成物理地址。

![img](https://img-blog.csdnimg.cn/08a8e315fedc4a858060db5cb4a654af.png)

内存分页是如何解决内存分段机制的缺点：外部内存碎片和内存交换效率低的问题？
内存分页由于内存空间都是预先划分好的，页与页之间是紧密排列，也就不会像内存分段一样，在段与段之间产生内存碎片。如果内存空间不够，操作系统会把最近没被使用的内存页面给写到硬盘，由于一次性内存交换的只有少数的页，不会花太多时间。

分页机制下，虚拟地址和物理地址是如何映射的？
在内存分页机制下，虚拟地址分为两个部分，页号和页内偏移量。页号作为页表的索引，页表包含物理页所在物理内存的基地址。因此 基地址 + 页内偏移量 = 物理内存地址。

![img](https://img-blog.csdnimg.cn/7884f4d8db4949f7a5bb4bbd0f452609.png)

简单的分页存在什么缺陷？
存在空间上的缺陷。在32位环境下，虚拟地址空间有4GB，假设一个页的大小是4kb，那么就需要大约100万个页，每个页表项需要4个字节大小来存储，那么整个4GB空间的映射需要4MB内存来存储页表。由于每个进程都是有自己的虚拟地址空间，也就是自己的页表。那么100个进程就需要400MB的内存来存储页表。

### 多级页表

要解决上面的问题，就需要采用一种叫做多级页表方案。一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建。引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。

我们把这个100多万个页表项进行再分页，将页表（一级页表）分为1024个页表（二级页表），每个二级页表包含1024个页表项。形成二级页表。如：

![img](https://img-blog.csdnimg.cn/19296e249b2240c29f9c52be70f611d5.png)

如果使用了二级分页，一级页表就可以覆盖整个4GB的虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表对应的二级页表（计算机局部性原理）。



## 3.段页式内存管理

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；
- 这样的地址结构就由  **段号+段内页号+页内位移**       三部分组成。

**Linux 内存主要采用的是页式内存管理**



虚拟内存的作用
第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。







## 内存页面置换算法

```
缺页中断：当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

最佳页面置换算法（OPT）：置换在「未来」最长时间不访问的页面，理想，但是实际系统中无法实现。
先进先出置换算法（FIFO）：选择在内存驻留时间最长的页面进行中置换
最近最久未使用的置换算法（LRU）：选择最长时间没有被访问的页面进行置换。需要记录一个页面上次访问的时间。维护一个链							 表，最多使用的页面在表头，最近最少使用的页面在表尾。缺点频繁移动链表耗时
时钟页面置换算法（CLock）：把所有的页面都保存在一个类似钟面的「环形链表」中，把沿途遇到的访问位为1的修改为0，直到						遇到访问位为0的页面，并将其淘汰，将新的页面插入到这个位置。
最不常用置换算法（LFU）：淘汰访问次数最少的页面,如果访问次数是一样的情况下，淘汰掉最近最久未使用的（lru）
```

## 磁盘调度算法

```
先来先服务算法：
最短寻道时间优先算法L:优先选择从当前磁头位置所需寻道时间最短的请求
扫描算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。
循环扫描算法：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，返回中途不处理任何请求。
LOOK 与 C-LOOK 算法：磁头在移动到「最远的请求」（不是最后的磁道）位置，然后立即反向移动。
```

## 内存分配、回收

![img](https://img-blog.csdnimg.cn/e069da38c4b54ee98a585a176e2c342f.png)

**内存的分配过程：**

```
应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。只有当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断。

如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。
后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程执行。
直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的			执行。
如果直接内存回收仍无法满足此次物理内存的申请，则触发OOM机制：根据算法选择杀死一个占用物理内存较高的进程。
```

<img src="https://img-blog.csdnimg.cn/2f61b0822b3c4a359f99770231981b07.png" alt="img" style="zoom: 67%;" />



## 哪些内存可以被回收？

```
主要有两类内存可以被回收，而且它们的回收方式也不同。
文件页：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存，因为脏页的数据还没有写到磁盘。

匿名页：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。
```

## 如何保护一个进程不被 OOM 杀掉呢？

```
oom选择kill掉的进程算法：
它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。
进程得分的结果受下面这两个方面影响：
第一，进程已经使用的物理内存页面数。   第二，每个进程的 OOM 校准值 oom_score_adj。
用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数。
points = process_pages + oom_score_adj*totalpages/1000   
```



## 虚拟内存大小

```
应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。
32位系统的虚拟内存大小最大为4G，其中系统内核空间占用1G，用户空间为3G
64位系统的内核空间和用户空间都是128T。
因此，在32位系统，4Gb物理内存的机器上，申请 8GB 内存，会失败。
而在64位系统，4Gb物理内存的机器上，申请 8GB 内存没有问题。

程序申请的虚拟内存，如果没有被使用，它是不会占用物理空间的。当访问这块虚拟内存后，操作系统才会进行物理内存分配。
如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制：
如果没有开启 Swap 机制，程序就会直接 OOM；
如果有开启 Swap 机制，程序可以正常运行。
```



# 文件系统

## 软链接和硬链接

![image-20220904205216753](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220904205216753.png)

![硬链接](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A1%AC%E9%93%BE%E6%8E%A5-2.png)

![image-20220904205239662](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220904205239662.png)

![软链接](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%BD%AF%E9%93%BE%E6%8E%A5.png)



## 文件I/O

[Java IO 模型详解 | JavaGuide(Java面试 + 学习指南)](https://javaguide.cn/java/io/io-model.html#何为-i-o)

```
IO模型可以大致分为两种

阻塞与非阻塞 I/O
阻塞 I/O：当应用程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区		  中，当拷贝过程完成，read 才会返回。
非阻塞 I/O：非阻塞的 read 请求在数据未准备好的情况下立即返回，不断轮询，直到数据准备好。为了解决这种轮询方式，发明了I/O 多路复用。如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I/O 多路复用接口的线程，然后用户可以进行后续的事件处理。

同步和异步I/O
同步I/O：无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数		   据从内核空间拷贝到应用程序空间的过程都是需要等待的。
异步I/O：发起系统调用后，立刻返回。内核自动将数据从内核空间拷贝到应用程序空间。「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。
```

![image-20220904212012282](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220904212012282.png)

**阻塞 I/O**

![阻塞 I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%98%BB%E5%A1%9E%20I_O.png)

NIO  -- 同步非阻塞IO模型，如下所示。

![非阻塞 I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20.png)



**I/O 多路复用模型**

IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。

![img](https://oss.javaguide.cn/github/javaguide/java/io/88ff862764024c3b8567367df11df6ab~tplv-k3u1fbpfcp-watermark.png)



## 进程发生了崩溃，已写入的数据会丢失吗

```
因为进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。

内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。
```

![img](https://img-blog.csdnimg.cn/img_convert/1541c881598f554920355f0a3c5780fd.png)

## Page Cache 是什么？

红色部分为 Page Cache。可见 Page Cache 的本质是由 Linux 内核管理的内存区域。我们通过 mmap 以及 buffered I/O 将文件读取到内存空间实际上都是读取到 Page Cache 中。对磁盘上 page（页）的内存缓存。

<img src="https://img-blog.csdnimg.cn/img_convert/72568a29816fa9b505f15edac68adee2.png" alt="img" style="zoom:67%;" />

```
PageCache的作用
1.缓存最近被访问的数据：程序运行的局部性，刚被访问的数据在短时间内再次被访问的概率很高。
2.预读功能：操作系统会将目标数据块的周围数据块都一起加载到内存。

Page Cache 与文件持久化的一致性&可靠性
当前 Linux 下以两种方式实现文件一致性：
1. **Write Through（写穿）**：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；
2. **Write back（写回）**：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；

Page Cache 优势：1.加快数据访问，2.减少 I/O 次数，提高系统磁盘 I/O 吞吐量
劣势：最直接的缺点是需要占用额外物理内存空间，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。
```



# 设备管理

## 设备控制器

```
数据寄存器：CPU 向 I/O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 			I/O 设备。
命令寄存器：接收cpu的指令。
状态寄存器:保存设备的状态，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，			 状态寄存标记成已完成，CPU 才能发送下一个字符和命令。
数据缓冲区：CPU 写入数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才发给设备。反之cpu从缓冲区中读取数据亦然
```

## 键盘敲入字母时，期间发生了什么？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/CPU%20%E7%A1%AC%E4%BB%B6%E6%80%BB%E7%BA%BF%E5%9B%BE.png" alt="CPU 的硬件架构图" style="zoom: 67%;" />

```
1.当用户输入了键盘字符，键盘控制器就会扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给cpu发送中断请求。
2.cpu收到中断请求后，操作系统会保存被中断进程的cpu上下文，然后调用键盘的中断处理程序。
3.键盘的中断处理程序是在键盘驱动程序初始化时注册的，功能是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，并转成ASCII码，并把这个码放到读缓冲区队列里。显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。
4.显示出结果后，恢复被中断进程的上下文
```



## 软中断和硬中断

```
硬中断
1. 硬中断是外部设备对CPU的中断；比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）.
2.硬中断是外部设备对CPU的中断，处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。
3.硬中断是由外部事件引起的因此具有随机性和突发性，可屏蔽

软中断
1.当前正在运行的进程所产生的。
2.软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。
3.软中断是执行中断指令产生的，无面外部施加中断请求信号，因此中断的发生不是随机的而是由程序安排好的。不可屏蔽
```

## **DMA（直接内存访问）**

```
中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 DMA。它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I/O 数据放入到内存。
DMA 的工作方式如下：
1.CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；
2.接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输   到内存；
3.当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；
4.DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/DMA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png)

## 为什么要有DMA技术

```
在没有 DMA 技术前，I/O 的过程是这样的：
1.CPU 发出对应的指令给磁盘控制器，然后返回；
2.磁盘控制器收到指令后，于是就开始准备数据，把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；注意不放在内存
3.CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。 
有了DMA技术，可以不用cpu亲自把数据写入到内存中，从而可以处理其他事务。
```



# 网络系统

## 传统的文件传输

```
发生四次数据拷贝，其中两次是DMA拷贝，两次是CPU拷贝。
第一次拷贝：把磁盘上的数据拷贝到操作系统内核的缓冲区里。 DMA
第二次拷贝：把内核缓冲区的数据拷贝到用户的缓冲区里，这样应用程序就可以使用这部分数据。CPU
第三次拷贝：把数据从用户缓冲区拷贝到内核的socket缓冲区。CPU
第三次拷贝：把内核的socket缓冲区的数据，拷贝到网卡的缓冲区。DMA
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png)





## 零拷贝

```
零拷贝技术实现的方式通常有 2 种：1.mmap + write； 2.sendfile  都是系统调用函数
mmap + write：  
由于read()函数的调用过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。mmap() 函数会直接把内核缓冲区里的数据「映射」到用户空间，从而无需数据拷贝操作。
过程如下：
1.应用进程调用mmap()后，DMA会把磁盘的数据拷贝到内核的缓冲区里，然后应用进程和操作系统内核共享这个缓冲区
2.应用进程再调用write()，操作系统直接将内核缓冲区的数据拷贝到socket缓冲区中，都发生在内核态，由CPU搬运数据。
3.最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。
缺点：1需要cpu把内核缓冲区的数据拷贝到 socket 缓冲区。2.仍然需要 4 次上下文切换
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png)

```
sendfile：
Linux 内核2.1版本，提供了一个专门发送文件的系统调用函数 sendfile()。替代前面的 read() 和 write() 这两个系统调用。可以减少一次系统调用，也就减少了 2 次上下文切换的开销。
其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态。但这不是真正的零拷贝技术

真正零拷贝技术：sendfile + SG-DMA   
零拷贝：没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。
第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里。不需要将数据拷贝到socket缓冲区。全程通过DMA传输。只需要两次上下文切换和数据拷贝次数。
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png)

真正的零拷贝技术：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png)



## 大文件传输用什么方式实现？

```
大文件传输不能使用pageCache，原因：
1.PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；
2.传输大文件（GB 级别的文件）的时候，PageCache 会不起作用（文件数据被再次访问的概率比较低），那就白白浪费 DMA 多做的一次数据拷贝。

针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。
```



## I/O 多路复用

```Java
多路复用：多个请求复用了一个进程。一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程。
    
 文件描述符：每一个进程都有一个数据结构 task_struct，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。数组的下标是文件描述符，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是内核可以通过文件描述符找到对应打开的文件。
    
select/poll/epoll 是如何获取网络事件的呢？
在获取事件时，先把我们要关心的连接传给内核，再由内核检测：
如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮训调用 read 操作来判断是否有数据。
如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回，然后在用户态中再处理这些连接对应的业务即可。
    
select实现多路复用的方式：
1.将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里
2.让内核来通过遍历方式来检查是否有网络事件产生。
3.当检查到有事件产生后，将此 Socket 标记为可读或可写。
4.再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。

select的缺点：
1.使用固定长度的 BitsMap来表示文件描述符集合，所支持的文件描述符的个数限制。
2.发生了2 次「遍历」文件描述符集合，2 次「拷贝」文件描述符集合。

poll 实现多路复用的方式：
poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制。
但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合。

epoll实现多路复用的方式：
第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字。把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，增删改一般时间复杂度是 O(logn) ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的socket的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

epoll支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/epoll.png)



## 高性能网络模式：Reactor 和 Proactor

Reactor 模式也叫 `Dispatcher` 模式，即 **I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程**。Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；

### 单 Reactor 单进程 / 线程

```
Reactor 对象的作用是监听和分发事件；Acceptor 对象的作用是获取连接；Handler 对象的作用是处理业务；
对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。

单 Reactor 单进程流程：
1.Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；
2.如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；
3.如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；
4.Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。Redis6.0版本之前采用的这种模式
```

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B.png)



### 单 Reactor 多线程 / 多进程

```
单 Reactor 多线程 / 多进程流程：
1.Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；
2.如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；
3.如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；
4.Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；
5.子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；
```

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img" style="zoom:75%;" />



###  异步的Proactor

![image-20220905212413687](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220905212413687.png)

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/Proactor.png)

# 一致性哈希算法

对于分布式存储，不同机器上存储不同对象的数据，我们使用哈希函数建立从数据到服务器之间的映射关系。

普通的哈希算法问题：**如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据**。

```
一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，称为哈希环。
一致性哈希要进行哈希：
第一步：对存储节点进行哈希计算，比如根据节点的 IP 地址进行哈希，顺一位节点；

一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。
寻址：对数据进行哈希计算的结果往顺时针的方向的第一个节点，就是存储该数据的节点
```

![img](https://img-blog.csdnimg.cn/img_convert/30c2c70721c12f9c140358fbdc5f2282.png)

```
在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。
缺点：一致性哈希算法并不保证节点能够在哈希环上分布均匀。
```

## 如何通过虚拟节点提高均衡度

```
具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。
虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。
还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟节点。
```



# 常用Linux命令

```
一、目录操作命令
1、目录切换
cd /  切换到根目录   cd /usr  切换到根目录下的usr目录   cd ..  切换到上一级目录 

2、目录查看  ls 查看当前目录下的所有文件

3、创建目录  mkdir qq  在当前目录下创建一个名为qq的目录
   删除目录  rm -r qq  递归删除当前目录下的qq目录    rm-rf qq 则不询问就删除
   拷贝目录  cp -r 目录名称 拷贝到哪里去   如：cp  /usr/lib/qq

4、查看文件  
可以先使用 ls -lh 查看日志文件的大小，如果文件小才在线上环境分析问题。
慎用cat命令，因为cat是日志文件数据量有多少，它就读多少，不适用大文件。
应该使用less 命令，因为 less 并不会加载整个文件，而是按需加载，先是输出一小页的内容，当要往下看的时候，才继续加载

二、进程相关
查看当前进程 ps   查看所有进程 ps -ef  结束进程kill  查看进程占用cpu情况，按从大到小, top命令

修改文件权限 chmod    搜索grep

```



如何查看进程的状态

1. 如何查看进程、Java线程状态
   1. ps -l, 列出的是详细信息 
   2. ![image-20240104205345145](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240104205345145.png)

   3.  F 代表这个程序的旗标 (flag)， 4 代表使用者为 superuser；

   4.  S 代表这个程序的状态 (STAT)；

   5.  （  常见的进程的 STAT 如下：

   6.  R 运行 Runnable (on run queue) 正在运行或在运行队列中等待，

   7.  S 睡眠 Sleeping 休眠中, 受阻, 在等待某个条件的形成或接受到信号，

   8.   I  空闲 Idle ，

   9.  Z 僵死 Zombie（a defunct process) 进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放，

   10.  D 不可中断 Uninterruptible sleep (ususally IO) 收到信号不唤醒和不可运行, 进程必须等待直到有中断发生，

   11.  T 终止 Terminate 进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行，

   12.  P 等待交换页 ，

   13.  W 无驻留页 has no resident pages 没有足够的记忆体分页可分配，

   14.  X 死掉的进程 ，

   15. 

   16.  ps  -aux ( ps -aux | grep ***,  列出 *** 进程的详细信息) 
   17. ![image-20240104205354100](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240104205354100.png)
   18.  USER ：进程的所属用户，

   19.  PID ：进程的进程ID号，

   20.  %CPU ：进程占用的 CPU资源 百分比，

   21.  %MEM ：进程占用的 物理内存 百分比，

   22.  VSZ ：进程使用掉的虚拟内存量 (Kbytes) ，

   23.  RSS ：进程占用的固定的内存量 (Kbytes) ，

   24.  TTY ：与进程相关联的终端（tty),?代表无关,tty1-tty6是本机上面的登入者程序,pts/0表示为由网络连接进主机的程序。

   25.  STAT ：进程的状态，具体见2.1列出来的部分 ，

   26.  START ：进程开始创建的时间 ，

   27.  TIME ：进程使用的总cpu时间，

   28.  COMMAND : 进程对应的实际程序。
